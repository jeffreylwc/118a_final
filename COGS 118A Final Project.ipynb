{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "#from sklearn import neighbors\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoverType: cover_type 2 (+1) vs Others (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    283301\n",
      "Name: 54, dtype: int64\n",
      "(581012, 54)\n",
      "(581012, 1)\n"
     ]
    }
   ],
   "source": [
    "covtype = pd.read_csv('covtype.data', header=None)\n",
    "encoded_covtype = covtype.copy()\n",
    "\n",
    "print(covtype[54].value_counts()[0:1]) #Find which value occurs the most\n",
    "\n",
    "#Set value 2 in column 54 as +1, others as -1\n",
    "encoded_covtype[54] = encoded_covtype[54].apply(lambda x: -1 if x != 2 else 1)\n",
    "\n",
    "covtype_array = encoded_covtype.to_numpy().astype(np.float)  #Convert df to np array\n",
    "X_covtype = covtype_array[:, :-1]                               \n",
    "Y_covtype = covtype_array[:, -1].reshape(-1,1)\n",
    "covtype_array = np.hstack((X_covtype, Y_covtype))  #Stack\n",
    "\n",
    "print(X_covtype.shape)  # (581012, 54)\n",
    "print(Y_covtype.shape)  # (581012, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adult:  > 50k income (+1) vs  <= 50k income (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 105)\n",
      "(32561, 1)\n"
     ]
    }
   ],
   "source": [
    "adult = pd.read_csv('adult.data', header=None)\n",
    "encoded_adult = adult.copy()\n",
    "\n",
    "#Clean data\n",
    "encoded_adult = encoded_adult.replace(' ?', np.nan) #change all missing data to np.nan\n",
    "encoded_adult[14] = encoded_adult[14].apply(lambda x: -1 if x == ' <=50K' else 1)  #Encode >50k as +1, otherwise -1\n",
    "\n",
    "Y_adult = encoded_adult[14].to_numpy().astype(np.float).reshape(-1, 1)\n",
    "\n",
    "encoded_adult = pd.get_dummies(encoded_adult[encoded_adult.columns[:-1]])   #One-hot encoding all categorical data\n",
    "\n",
    "X_adult = encoded_adult.to_numpy().astype(np.float)\n",
    "\n",
    "adult_array = np.hstack((X_adult, Y_adult)) # stack\n",
    "\n",
    "print(X_adult.shape) # (32561, 105)\n",
    "print(Y_adult.shape) # (32561, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letter Recognition: A-M (+1) vs N-Z (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('covtype.info', 'r') as covtype_info:\n",
    "    #print(covtype_info.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 16)\n",
      "(20000, 1)\n"
     ]
    }
   ],
   "source": [
    "letter = pd.read_csv('letter-recognition.data', header=None) # Load dataset letter-recognition\n",
    "encoded_letter = letter.copy()  # Copy original data\n",
    "\n",
    "encoded_letter[17] = letter[0] < 'N'  #Create a column where 'A-M' are True, others are False\n",
    "encoded_letter = encoded_letter.replace(False, -1) #Replace False to -1, True to +1  \n",
    "encoded_letter = encoded_letter.drop(0, axis=1)  #Drop first column containing letters\n",
    "\n",
    "letter_array = encoded_letter.to_numpy().astype(np.float) #Convert dataframe to numpy array\n",
    "\n",
    "X_letter = encoded_letter.to_numpy().astype(np.float)[:, :-1]  \n",
    "Y_letter = encoded_letter.to_numpy().astype(np.float)[:, -1].reshape(-1,1)\n",
    "\n",
    "print(X_letter.shape)  #(20000,16)\n",
    "print(Y_letter.shape)  #(20000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Algorithms and their parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Random Forest CV\n",
    "max_depth = [1,2,3,4,5]\n",
    "max_feature = [1,2,4,6,8,12,16,20]\n",
    "n_estimators = 1024\n",
    "\n",
    "# parameters for Logistic Regression \n",
    "C_list = [0.00000001, 0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000]\n",
    "\n",
    "# paramters for KNN\n",
    "n_neighbors = np.logspace(1, 500, 25)\n",
    "\n",
    "models = []\n",
    "models.append(('RF', RandomForestClassifier(n_estimators= n_estimators)))\n",
    "models.append(('LOGREG', LogisticRegression()))\n",
    "models.append(('KNN', KNeighborsClassifier(metric='euclidean')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation for Adult dataset\n",
    "\n",
    "# Random 5000 samples \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_adult, Y_adult,\n",
    "                                                   train_size=5000)\n",
    "\n",
    "# Create a pipeline \n",
    "pipe = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', RandomForestClassifier(n_estimators=n_estimators))])\n",
    "\n",
    "# Create search space of learning algorithms \n",
    "search_space = [{'classifier': [LogisticRegression(solver='saga')],\n",
    "                'classifier__penalty': ['l1', 'l2'],\n",
    "                'classifier__C': n_neighbors},\n",
    "                {'classifier': [RandomForestClassifier()],\n",
    "                 'classifier__max_features': max_feature},\n",
    "                {'classifier': [KNeighborsClassifier(metric='euclidean')],\n",
    "                 'classifier__n_neighbors': n_neighbors}]\n",
    "\n",
    "# Create grid search\n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features=20,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1024,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_estimator_.get_params()['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features=4,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Random 5000 samples \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_letter, Y_letter,\n",
    "                                                   train_size=5000)\n",
    "\n",
    "# Create a pipeline \n",
    "pipe = Pipeline([('std', StandardScaler()),\n",
    "                 ('classifier', RandomForestClassifier(n_estimators=n_estimators))])\n",
    "\n",
    "# Create search space of learning algorithms \n",
    "search_space = [{'classifier': [LogisticRegression(solver='saga')],\n",
    "                'classifier__penalty': ['l1', 'l2'],\n",
    "                'classifier__C': n_neighbors},\n",
    "                {'classifier': [RandomForestClassifier()],\n",
    "                 'classifier__max_features': max_feature},\n",
    "                {'classifier': [KNeighborsClassifier(metric='euclidean')],\n",
    "                 'classifier__n_neighbors': n_neighbors}]\n",
    "\n",
    "# Create grid search\n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0)\n",
    "\n",
    "# Fit grid search\n",
    "best_model = clf.fit(X_train, Y_train)\n",
    "best_model.best_estimator_.get_params()['classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms for Adult dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation for Adult dataset\n",
    "\n",
    "# Random 5000 samples \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_adult, Y_adult,\n",
    "                                                   train_size=5000)\n",
    "\n",
    "# Initiating Classifiers\n",
    "clf1 = LogisticRegression()\n",
    "\n",
    "clf2 = KNeighborsClassifier()\n",
    "\n",
    "clf3 = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "# Building the pipeliens\n",
    "pipe1 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf1)])\n",
    "\n",
    "pipe2 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf2)])\n",
    "\n",
    "pipe3 = Pipeline([('std', StandardScaler()),\n",
    "                  ('classifier', clf3)])\n",
    "\n",
    "# Setting up the parameter grids\n",
    "param_grid1 = [{'classifier__penalty': ['l2'],\n",
    "                'classifier__C': np.power(10., np.arange(-8, 4))}]\n",
    "\n",
    "param_grid2 = [{'classifier__n_neighbors': np.linspace(1, 500, 25).astype(int)}]\n",
    "\n",
    "param_grid3 = [{'classifier__max_features': max_feature}]\n",
    "\n",
    "# Settign up multiple GridSearch \n",
    "gridcvs = {}\n",
    "\n",
    "for pgrid, est, name in zip((param_grid1, param_grid2, param_grid3), \n",
    "                            (pipe1, pipe2, pipe3),\n",
    "                            ('Logistic', 'KNN', 'RandomForest')):\n",
    "    gcv = GridSearchCV(estimator=est,\n",
    "                      param_grid=pgrid,\n",
    "                      scoring='accuracy',\n",
    "                      n_jobs=1,\n",
    "                      cv=5,\n",
    "                      verbose=0,\n",
    "                      refit=True)\n",
    "    gridcvs[name] = gcv\n",
    "\n",
    "cv_scores = {name: [] for name, gs_est in gridcvs.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = gcv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features=4,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.best_estimator_.get_params()['classifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, gs_est in sorted(gridcvs.items()):\n",
    "    gs_est.fit(X_train, y_train)\n",
    "    y_pred = gs_est.predict(X_train)\n",
    "    acc = accuracy_score(y_true=y_train, y_pred=y_pred)\n",
    "    cv_scores[name].append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic': [0.8626], 'KNN': [0.8356], 'RandomForest': [1.0]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic | outer CV acc. 86.26% +\\- 0.000\n",
      "KNN      | outer CV acc. 83.56% +\\- 0.000\n",
      "RandomForest | outer CV acc. 100.00% +\\- 0.000\n",
      "\n",
      "Logistic best parameters {'classifier__C': 0.1, 'classifier__penalty': 'l2'}\n",
      "KNN best parameters {'classifier__n_neighbors': 104}\n",
      "RandomForest best parameters {'classifier__max_features': 12}\n"
     ]
    }
   ],
   "source": [
    "for name in cv_scores:\n",
    "    print('%-8s | outer CV acc. %.2f%% +\\- %.3f' % (\n",
    "           name, 100*np.mean(cv_scores[name]), 100 * np.std(cv_scores[name])))\n",
    "    \n",
    "print()\n",
    "for name in cv_scores:\n",
    "    print('{} best parameters'.format(name), gridcvs[name].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 86.18% (average over CV test folds)\n",
      "Best parameters: {'classifier__max_features': 16}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 84.66%\n"
     ]
    }
   ],
   "source": [
    "best_algo = gridcvs['RandomForest']\n",
    "\n",
    "best_algo.fit(X_train, y_train)\n",
    "train_acc = accuracy_score(y_true=y_train, y_pred=best_algo.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=y_test, y_pred=best_algo.predict(X_test))\n",
    "\n",
    "\n",
    "# want to calculate scores\n",
    "\n",
    "print('Accuracy %.2f%% (average over CV test folds)' %\n",
    "      (100 * best_algo.best_score_))\n",
    "print('Best parameters: %s' % gridcvs['RandomForest'].best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7822\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 21, 'p': 2, 'weights': 'uniform'}\n",
      "Best parameters: {'n_neighbors': 21}\n",
      "Training Accuracy: 78.88%\n",
      "Test Accuracy: 78.30%\n"
     ]
    }
   ],
   "source": [
    "# Random 5000 samples \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_adult, Y_adult,\n",
    "                                                   train_size=5000)\n",
    "\n",
    "p_grid = {'n_neighbors': np.linspace(1, 500, 25).astype(int)}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(estimator=knn, param_grid=p_grid, cv=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(clf.best_score_)\n",
    "print(clf.best_estimator_.get_params())\n",
    "\n",
    "train_acc = accuracy_score(y_true=Y_train, y_pred=clf.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=Y_test, y_pred=clf.predict(X_test))\n",
    "\n",
    "print('Best parameters: %s' % clf.best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8421999999999998"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 16,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 1024,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_features': 16}\n",
      "Training Accuracy: 99.98%\n",
      "Test Accuracy: 85.23%\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "train_acc = accuracy_score(y_true=Y_train, y_pred=clf.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=Y_test, y_pred=clf.predict(X_test))\n",
    "\n",
    "\n",
    "print('Best parameters: %s' % clf.best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-134-3de15ac7a234>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0madult_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mletter_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovtype_array\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "datasets = [adult_array, letter_array, covtype_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one trial \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_adult, Y_adult,\n",
    "                                                   train_size=5000)\n",
    "\n",
    "p_grid = {'max_features': max_feature}\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "clf = GridSearchCV(estimator=rf, param_grid=p_grid, cv=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(clf.bets_score)\n",
    "print(clf.best_estimator_.get_params())\n",
    "\n",
    "train_acc = accuracy_score(y_true=Y_train, y_pred=clf.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=Y_test, y_pred=clf.predict(X_test))\n",
    "\n",
    "print('Best parameters: %s' % clf.best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [ 1.],\n",
       "       ...,\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [-1.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covtype_array[:, -1].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.90000e+01, 7.75160e+04, 1.30000e+01, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [5.00000e+01, 8.33110e+04, 1.30000e+01, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [3.80000e+01, 2.15646e+05, 9.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       ...,\n",
       "       [5.80000e+01, 1.51910e+05, 9.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [2.20000e+01, 2.01490e+05, 9.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00],\n",
       "       [5.20000e+01, 2.87927e+05, 9.00000e+00, ..., 1.00000e+00,\n",
       "        0.00000e+00, 0.00000e+00]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult_array[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.],\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       ...,\n",
       "       [-1.],\n",
       "       [-1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random 5000 samples \n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_adult, Y_adult,\n",
    "                                                   train_size=5000)\n",
    "\n",
    "p_grid = {'n_neighbors': np.linspace(1, 500, 25).astype(int)}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "clf = GridSearchCV(estimator=knn, param_grid=p_grid, cv=5)\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "print(clf.best_score_)\n",
    "print(clf.best_estimator_.get_params())\n",
    "\n",
    "train_acc = accuracy_score(y_true=Y_train, y_pred=clf.predict(X_train))\n",
    "test_acc = accuracy_score(y_true=Y_test, y_pred=clf.predict(X_test))\n",
    "\n",
    "print('Best parameters: %s' % clf.best_params_)\n",
    "print('Training Accuracy: %.2f%%' % (100 * train_acc))\n",
    "print('Test Accuracy: %.2f%%' % (100 * test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean cross-validated score of the best_estimator: 0.7924\n",
      "Parameters: {'C': 0.001, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Best parameters: {'C': 0.001}\n",
      "Training Accuracy: 79.26%\n",
      "Test Accuracy: 79.74%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.7708\n",
      "Parameters: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 21, 'p': 2, 'weights': 'uniform'}\n",
      "Best parameters: {'n_neighbors': 21}\n",
      "Training Accuracy: 77.78%\n",
      "Test Accuracy: 78.48%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.8468\n",
      "Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 12, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 1024, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Best parameters: {'max_features': 12}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 85.03%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.7948000000000002\n",
      "Parameters: {'C': 1e-06, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Best parameters: {'C': 1e-06}\n",
      "Training Accuracy: 79.70%\n",
      "Test Accuracy: 79.57%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.7796000000000001\n",
      "Parameters: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 21, 'p': 2, 'weights': 'uniform'}\n",
      "Best parameters: {'n_neighbors': 21}\n",
      "Training Accuracy: 78.52%\n",
      "Test Accuracy: 78.64%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.852\n",
      "Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 20, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 1024, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Best parameters: {'max_features': 20}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 85.23%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.79\n",
      "Parameters: {'C': 1e-05, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Best parameters: {'C': 1e-05}\n",
      "Training Accuracy: 79.00%\n",
      "Test Accuracy: 79.94%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.7716000000000001\n",
      "Parameters: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 21, 'p': 2, 'weights': 'uniform'}\n",
      "Best parameters: {'n_neighbors': 21}\n",
      "Training Accuracy: 77.66%\n",
      "Test Accuracy: 78.79%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.8521999999999998\n",
      "Parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 16, 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 1024, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "Best parameters: {'max_features': 16}\n",
      "Training Accuracy: 100.00%\n",
      "Test Accuracy: 85.13%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.7354\n",
      "Parameters: {'C': 100.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Best parameters: {'C': 100.0}\n",
      "Training Accuracy: 73.64%\n",
      "Test Accuracy: 72.59%\n",
      "\n",
      "\n",
      "Mean cross-validated score of the best_estimator: 0.9533999999999999\n",
      "Parameters: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 1, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets: # for loop for each of the three datasets\n",
    "    features = dataset[:, :-1]  # get X (features) from each of the datasets\n",
    "    labels = dataset[:, -1].reshape(-1,1) # get Y (labels) from each of the datasets\n",
    "    \n",
    "    for trial in range(3): # Loop through 3 trials for each dataset\n",
    "        # 5000 random samples \n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(features, labels,\n",
    "                                                       train_size=5000)\n",
    "        \n",
    "        # Algorithm 1/3 LOGREG\n",
    "        logreg_p_grid = {'C': np.power(10., np.arange(-8, 4))}\n",
    "        \n",
    "        logreg = LogisticRegression()\n",
    "\n",
    "        logreg_clf = GridSearchCV(estimator=logreg, param_grid=logreg_p_grid, cv=5)\n",
    "        logreg_clf.fit(X_train, Y_train)\n",
    "\n",
    "        print('Mean cross-validated score of the best_estimator: %s' % logreg_clf.best_score_)\n",
    "        print('Parameters: %s' % logreg_clf.best_estimator_.get_params())\n",
    "\n",
    "        logreg_train_acc = accuracy_score(y_true=Y_train, y_pred=logreg_clf.predict(X_train))\n",
    "        logreg_test_acc = accuracy_score(y_true=Y_test, y_pred=logreg_clf.predict(X_test))\n",
    "\n",
    "        print('Best parameters: %s' % logreg_clf.best_params_)\n",
    "        print('Training Accuracy: %.2f%%' % (100 * logreg_train_acc))\n",
    "        print('Test Accuracy: %.2f%%' % (100 * logreg_test_acc))\n",
    "        print('\\n')\n",
    "\n",
    "        \n",
    "        \n",
    "        # Algorithm 2/3 KNN\n",
    "        knn_p_grid = {'n_neighbors': np.linspace(1, 500, 25).astype(int)}\n",
    "        \n",
    "        knn = KNeighborsClassifier()\n",
    "        \n",
    "        knn_clf = GridSearchCV(estimator=knn, param_grid=knn_p_grid, cv=5)\n",
    "        knn_clf.fit(X_train, Y_train)\n",
    "        \n",
    "        print('Mean cross-validated score of the best_estimator: %s' % knn_clf.best_score_)\n",
    "        print('Parameters: %s' % knn_clf.best_estimator_.get_params())\n",
    "\n",
    "        knn_train_acc = accuracy_score(y_true=Y_train, y_pred=knn_clf.predict(X_train))\n",
    "        knn_test_acc = accuracy_score(y_true=Y_test, y_pred=knn_clf.predict(X_test))\n",
    "\n",
    "        print('Best parameters: %s' % knn_clf.best_params_)\n",
    "        print('Training Accuracy: %.2f%%' % (100 * knn_train_acc))\n",
    "        print('Test Accuracy: %.2f%%' % (100 * knn_test_acc))\n",
    "        print('\\n')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Algorithm 3/3 RandomForest\n",
    "        p_grid_rf = {'max_features': max_feature} #hyperparameter for RandomForest\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators) # RandomForest classifier\n",
    "\n",
    "        rf_clf = GridSearchCV(estimator=rf, param_grid=p_grid_rf, cv=5) #5 fold GridSearch \n",
    "        \n",
    "        rf_clf.fit(X_train, Y_train)\n",
    "\n",
    "        print('Mean cross-validated score of the best_estimator: %s' % rf_clf.best_score_)\n",
    "        print('Parameters: %s' % rf_clf.best_estimator_.get_params())\n",
    "\n",
    "        rf_train_acc = accuracy_score(y_true=Y_train, y_pred=rf_clf.predict(X_train))\n",
    "        rf_test_acc = accuracy_score(y_true=Y_test, y_pred=rf_clf.predict(X_test))\n",
    "\n",
    "        print('Best parameters: %s' % rf_clf.best_params_)\n",
    "        print('Training Accuracy: %.2f%%' % (100 * rf_train_acc))\n",
    "        print('Test Accuracy: %.2f%%' % (100 * rf_test_acc))\n",
    "        print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
